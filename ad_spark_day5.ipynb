{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM4PgvrDxl7zU0MdVBD+C/d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mayureshpawashe/ad_spark/blob/main/ad_spark_day5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##UDFs & Future Updates"
      ],
      "metadata": {
        "id": "he71pIhuavdU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName('Ad Spark day3 ').getOrCreate()\n",
        "url = \"https://raw.githubusercontent.com/prasertcbs/basic-dataset/refs/heads/master/Employee%20data.csv\"\n",
        "file_path = \"/tmp/EMP_data.csv\"\n",
        "urllib.request.urlretrieve(url, file_path)\n",
        "df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
        "df.show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "quB1yCqyvfRV",
        "outputId": "12033e0b-008f-4680-f927-8aebc9ae9413"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+------+----------+----+--------+-------+--------+-------+-------+--------+\n",
            "|  id|gender|     bdate|educ|  jobcat| salary|salbegin|jobtime|prevexp|minority|\n",
            "+----+------+----------+----+--------+-------+--------+-------+-------+--------+\n",
            "| 1.0|  Male|1952-02-03|  15| Manager|57000.0| 27000.0|   98.0|  144.0|      No|\n",
            "| 2.0|  Male|1958-05-23|  16|Clerical|40200.0| 18750.0|   98.0|   36.0|      No|\n",
            "| 3.0|Female|1929-07-26|  12|Clerical|21450.0| 12000.0|   98.0|  381.0|      No|\n",
            "| 4.0|Female|1947-04-15|   8|Clerical|21900.0| 13200.0|   98.0|  190.0|      No|\n",
            "| 5.0|  Male|1955-02-09|  15|Clerical|45000.0| 21000.0|   98.0|  138.0|      No|\n",
            "| 6.0|  Male|1958-08-22|  15|Clerical|32100.0| 13500.0|   98.0|   67.0|      No|\n",
            "| 7.0|  Male|1956-04-26|  15|Clerical|36000.0| 18750.0|   98.0|  114.0|      No|\n",
            "| 8.0|Female|1966-05-06|  12|Clerical|21900.0|  9750.0|   98.0|missing|      No|\n",
            "| 9.0|Female|1946-01-23|  15|Clerical|27900.0| 12750.0|   98.0|  115.0|      No|\n",
            "|10.0|Female|1946-02-13|  12|Clerical|24000.0| 13500.0|   98.0|  244.0|      No|\n",
            "+----+------+----------+----+--------+-------+--------+-------+-------+--------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##UDF to Convert Gender to Uppercase"
      ],
      "metadata": {
        "id": "5pWeqms1-II8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import StringType, IntegerType\n",
        "import datetime\n",
        "def to_uppercase(gender):\n",
        "    return gender.upper() if gender else None  # Handling None values\n",
        "\n",
        "gender_udf = udf(to_uppercase, StringType())\n",
        "\n",
        "df = df.withColumn(\"gender_upper\", gender_udf(df.gender))\n",
        "df.show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DsCYj8TC-RDU",
        "outputId": "09204be8-c474-4a00-e1d5-561be8f9fa6a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+------+----------+----+--------+-------+--------+-------+-------+--------+------------+\n",
            "|  id|gender|     bdate|educ|  jobcat| salary|salbegin|jobtime|prevexp|minority|gender_upper|\n",
            "+----+------+----------+----+--------+-------+--------+-------+-------+--------+------------+\n",
            "| 1.0|  Male|1952-02-03|  15| Manager|57000.0| 27000.0|   98.0|  144.0|      No|        MALE|\n",
            "| 2.0|  Male|1958-05-23|  16|Clerical|40200.0| 18750.0|   98.0|   36.0|      No|        MALE|\n",
            "| 3.0|Female|1929-07-26|  12|Clerical|21450.0| 12000.0|   98.0|  381.0|      No|      FEMALE|\n",
            "| 4.0|Female|1947-04-15|   8|Clerical|21900.0| 13200.0|   98.0|  190.0|      No|      FEMALE|\n",
            "| 5.0|  Male|1955-02-09|  15|Clerical|45000.0| 21000.0|   98.0|  138.0|      No|        MALE|\n",
            "| 6.0|  Male|1958-08-22|  15|Clerical|32100.0| 13500.0|   98.0|   67.0|      No|        MALE|\n",
            "| 7.0|  Male|1956-04-26|  15|Clerical|36000.0| 18750.0|   98.0|  114.0|      No|        MALE|\n",
            "| 8.0|Female|1966-05-06|  12|Clerical|21900.0|  9750.0|   98.0|missing|      No|      FEMALE|\n",
            "| 9.0|Female|1946-01-23|  15|Clerical|27900.0| 12750.0|   98.0|  115.0|      No|      FEMALE|\n",
            "|10.0|Female|1946-02-13|  12|Clerical|24000.0| 13500.0|   98.0|  244.0|      No|      FEMALE|\n",
            "+----+------+----------+----+--------+-------+--------+-------+-------+--------+------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##UDF to Calculate Age from Birthdate"
      ],
      "metadata": {
        "id": "ReBpsCuy-9Lz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import udf, year\n",
        "from pyspark.sql.types import IntegerType\n",
        "import datetime\n",
        "def calculate_age(birth_year):\n",
        "    current_year = datetime.datetime.now().year\n",
        "    return current_year - birth_year if birth_year else None\n",
        "\n",
        "age_udf = udf(calculate_age, IntegerType())\n",
        "\n",
        "df1 = df.withColumn(\"age\", age_udf(year(df.bdate)))\n",
        "\n",
        "df1.show(10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CpIno1Sv--X0",
        "outputId": "858ab385-f582-4940-8ce9-9e1778022d5a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+------+----------+----+--------+-------+--------+-------+-------+--------+------------+---+\n",
            "|  id|gender|     bdate|educ|  jobcat| salary|salbegin|jobtime|prevexp|minority|gender_upper|age|\n",
            "+----+------+----------+----+--------+-------+--------+-------+-------+--------+------------+---+\n",
            "| 1.0|  Male|1952-02-03|  15| Manager|57000.0| 27000.0|   98.0|  144.0|      No|        MALE| 73|\n",
            "| 2.0|  Male|1958-05-23|  16|Clerical|40200.0| 18750.0|   98.0|   36.0|      No|        MALE| 67|\n",
            "| 3.0|Female|1929-07-26|  12|Clerical|21450.0| 12000.0|   98.0|  381.0|      No|      FEMALE| 96|\n",
            "| 4.0|Female|1947-04-15|   8|Clerical|21900.0| 13200.0|   98.0|  190.0|      No|      FEMALE| 78|\n",
            "| 5.0|  Male|1955-02-09|  15|Clerical|45000.0| 21000.0|   98.0|  138.0|      No|        MALE| 70|\n",
            "| 6.0|  Male|1958-08-22|  15|Clerical|32100.0| 13500.0|   98.0|   67.0|      No|        MALE| 67|\n",
            "| 7.0|  Male|1956-04-26|  15|Clerical|36000.0| 18750.0|   98.0|  114.0|      No|        MALE| 69|\n",
            "| 8.0|Female|1966-05-06|  12|Clerical|21900.0|  9750.0|   98.0|missing|      No|      FEMALE| 59|\n",
            "| 9.0|Female|1946-01-23|  15|Clerical|27900.0| 12750.0|   98.0|  115.0|      No|      FEMALE| 79|\n",
            "|10.0|Female|1946-02-13|  12|Clerical|24000.0| 13500.0|   98.0|  244.0|      No|      FEMALE| 79|\n",
            "+----+------+----------+----+--------+-------+--------+-------+-------+--------+------------+---+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##UDF to Categorize Salary"
      ],
      "metadata": {
        "id": "Je5tf2BvCBG5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import IntegerType\n",
        "from datetime import datetime\n",
        "\n",
        "# Fix the UDF\n",
        "def calculate_age(bdate):\n",
        "    if bdate is None:\n",
        "        return None\n",
        "    elif isinstance(bdate, str):  # If it's a string, convert to datetime\n",
        "        birth_year = int(bdate.split(\"-\")[0])\n",
        "    elif isinstance(bdate, datetime.date):  # If it's already a date object\n",
        "        birth_year = bdate.year\n",
        "    else:\n",
        "        return None\n",
        "    return datetime.now().year - birth_year\n",
        "\n",
        "# Register the UDF\n",
        "age_udf = udf(calculate_age, IntegerType())\n",
        "\n",
        "# Ensure `bdate` is of StringType before applying UDF\n",
        "df = df.withColumn(\"bdate\", df[\"bdate\"].cast(\"string\"))\n",
        "\n",
        "# Apply the UDF\n",
        "df = df.withColumn(\"age\", age_udf(df.bdate))\n",
        "\n",
        "# Show results\n",
        "df.show(10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nqi0IAGfCWiA",
        "outputId": "78c71747-042b-41b2-f0de-eb0dc5ccd057"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+------+----------+----+--------+------+--------+-------+-------+--------+------------+---+---------------+\n",
            "|  id|gender|     bdate|educ|  jobcat|salary|salbegin|jobtime|prevexp|minority|gender_upper|age|salary_category|\n",
            "+----+------+----------+----+--------+------+--------+-------+-------+--------+------------+---+---------------+\n",
            "| 1.0|  Male|1952-02-03|  15| Manager| 57000| 27000.0|   98.0|  144.0|      No|        MALE| 73|         Medium|\n",
            "| 2.0|  Male|1958-05-23|  16|Clerical| 40200| 18750.0|   98.0|   36.0|      No|        MALE| 67|         Medium|\n",
            "| 3.0|Female|1929-07-26|  12|Clerical| 21450| 12000.0|   98.0|  381.0|      No|      FEMALE| 96|            Low|\n",
            "| 4.0|Female|1947-04-15|   8|Clerical| 21900| 13200.0|   98.0|  190.0|      No|      FEMALE| 78|            Low|\n",
            "| 5.0|  Male|1955-02-09|  15|Clerical| 45000| 21000.0|   98.0|  138.0|      No|        MALE| 70|         Medium|\n",
            "| 6.0|  Male|1958-08-22|  15|Clerical| 32100| 13500.0|   98.0|   67.0|      No|        MALE| 67|            Low|\n",
            "| 7.0|  Male|1956-04-26|  15|Clerical| 36000| 18750.0|   98.0|  114.0|      No|        MALE| 69|            Low|\n",
            "| 8.0|Female|1966-05-06|  12|Clerical| 21900|  9750.0|   98.0|missing|      No|      FEMALE| 59|            Low|\n",
            "| 9.0|Female|1946-01-23|  15|Clerical| 27900| 12750.0|   98.0|  115.0|      No|      FEMALE| 79|            Low|\n",
            "|10.0|Female|1946-02-13|  12|Clerical| 24000| 13500.0|   98.0|  244.0|      No|      FEMALE| 79|            Low|\n",
            "+----+------+----------+----+--------+------+--------+-------+-------+--------+------------+---+---------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import IntegerType\n",
        "def square_number(n):\n",
        "    return n * n if n is not None else None  # Handle null values\n",
        "\n",
        "square_udf = udf(square_number, IntegerType())\n",
        "\n",
        "data = [(1,), (2,), (3,), (4,), (5,)]\n",
        "df = spark.createDataFrame(data, [\"number\"])\n",
        "\n",
        "df = df.withColumn(\"square\", square_udf(df[\"number\"]))\n",
        "\n",
        "df.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87L3CbOFR7p9",
        "outputId": "97854469-19be-4a2b-ffb7-7b0b030f82f6"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------+\n",
            "|number|square|\n",
            "+------+------+\n",
            "|     1|     1|\n",
            "|     2|     4|\n",
            "|     3|     9|\n",
            "|     4|    16|\n",
            "|     5|    25|\n",
            "+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Create a UDF to check if a value in a column is prime or not"
      ],
      "metadata": {
        "id": "VmysOPOFuKRx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import BooleanType\n",
        "\n",
        "# Define function to check if a number is prime\n",
        "def is_prime(n):\n",
        "    if n is None or n < 2:\n",
        "        return False\n",
        "    for i in range(2, int(n ** 0.5) + 1):\n",
        "        if n % i == 0:\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "is_prime_udf = udf(is_prime, BooleanType())\n",
        "df = df.withColumn(\"is_prime_educ\", is_prime_udf(df[\"educ\"]))\n",
        "df.select(\"educ\", \"is_prime_educ\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AINDdnmpAZZ",
        "outputId": "363cac17-6d08-41ac-9e13-3439b422ec31"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-------------+\n",
            "|educ|is_prime_educ|\n",
            "+----+-------------+\n",
            "|  15|        false|\n",
            "|  16|        false|\n",
            "|  12|        false|\n",
            "|   8|        false|\n",
            "|  15|        false|\n",
            "|  15|        false|\n",
            "|  15|        false|\n",
            "|  12|        false|\n",
            "|  15|        false|\n",
            "|  12|        false|\n",
            "|  16|        false|\n",
            "|   8|        false|\n",
            "|  15|        false|\n",
            "|  15|        false|\n",
            "|  12|        false|\n",
            "|  12|        false|\n",
            "|  15|        false|\n",
            "|  16|        false|\n",
            "|  12|        false|\n",
            "|  12|        false|\n",
            "+----+-------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    }
  ]
}